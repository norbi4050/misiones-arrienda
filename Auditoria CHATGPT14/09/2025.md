Auditoría Comparativa del Proyecto Actualizado

Informe Comparativo de Auditoría – Proyecto Next.js (Misiones Arrienda)

Este informe compara la versión actual del proyecto Misiones Arrienda con la versión anterior previamente auditada, enfocándose en si se implementaron las recomendaciones pasadas. Cada sección corresponde a un punto observado en la auditoría previa, indicando el estado actual: Resuelto, Parcialmente resuelto o Pendiente. Se incluyen ejemplos de código y detalles relevantes para respaldar cada evaluación.

1. Middleware de autenticación en Next.js (protección de rutas privadas)

Anterior: Se detectó que las rutas privadas no estaban suficientemente protegidas por middleware, lo que permitía el acceso no autorizado a páginas como el perfil de usuario, dashboard, etc.

 

Actual: Se implementó un middleware global (src/middleware.ts) que intercepta las rutas sensibles y verifica la sesión de Supabase antes de continuar. El código define una lista de rutas protegidas y redirige al login si el usuario no está autenticado. Por ejemplo, en el middleware actual se observa:

// Rutas que requieren autenticación
const protectedRoutes = ['/profile', '/dashboard', '/publicar'];

if (isProtectedRoute) {
  const { data: { session } } = await supabase.auth.getSession();
  if (!session) {
    const redirectUrl = new URL('/login', req.url);
    redirectUrl.searchParams.set('redirect', req.nextUrl.pathname);
    return NextResponse.redirect(redirectUrl);
  }
}


Esto garantiza que páginas como Perfil, Dashboard y Publicar requieran sesión activa. La implementación aprovecha la integración con Supabase (via createServerClient) para leer la cookie sb-access-token y obtener la sesión del usuario.

 

Conclusión: El middleware ahora protege correctamente las rutas privadas básicas. Sin embargo, notamos que rutas de administrador (ej. /admin) no fueron añadidas a la lista protectedRoutes, lo cual sería deseable. Aun así, las páginas críticas para usuarios estándar sí están cubiertas. Estado: Resuelto (con ligera observación).

2. Verificación de administrador en rutas backend sensibles

Anterior: Se señaló que ciertas rutas API sensibles (administración de usuarios, estadísticas, eliminación de usuarios, etc.) carecían de validación de rol administrador, permitiendo potencialmente que cualquier usuario autenticado las acceda.

 

Actual: En la versión actual, las rutas bajo /api/admin/* implementan validaciones de administrador utilizando Supabase. Por ejemplo, en src/app/api/admin/users/route.ts se verifica el token de sesión y luego el rol del usuario:

// Verificar autenticación
const token = cookieStore.get('sb-access-token')?.value;
if (!token) return NextResponse.json({ error: 'No autorizado' }, { status: 401 });

// Obtener usuario desde el token
const { data: { user } } = await supabaseClient.auth.getUser(token);
if (!user) return NextResponse.json({ error: 'Token inválido' }, { status: 401 });

// Verificar rol ADMIN en base de datos
const { data: userProfile } = await supabaseAdmin.from('User').select('role').eq('id', user.id).single();
if (userProfile?.role !== 'ADMIN') {
  return NextResponse.json({ error: 'Permisos insuficientes. Solo administradores.' }, { status: 403 });
}


Como se aprecia, se usa un cliente Supabase admin (clave de servicio) para consultar la tabla de usuarios y confirmar que el campo role sea 'ADMIN'. Solo en caso positivo se procede con la lógica de la ruta (listado de usuarios, borrado, etc.). Esta lógica de verificación de rol existe en admin/users y admin/delete-user, añadiendo la protección requerida.

 

Hallazgo: Aunque las rutas mencionadas ahora validan el rol correctamente, no todas las rutas de administrador lo hacen. En particular, las rutas de estadísticas y actividad administrativa (/api/admin/stats y /api/admin/activity) no implementan chequeo de administrador en su código. Estas todavía usan consultas directas (vía Prisma) sin verificar el usuario, lo cual supone un riesgo si alguien descubre esas URLs. Idealmente, todas las rutas bajo /api/admin deberían exigir token y rol admin.

 

Conclusión: Se avanzó significativamente en asegurar las rutas backend sensibles con verificación de administrador, aunque persisten omisiones en algunos endpoints de administrador. Estado: Parcialmente resuelto (requiere agregar checks en todos los endpoints admin).

3. Limpieza de código obsoleto o duplicado

Anterior: El proyecto contenía archivos “backup” o duplicados (sufijos -fixed, -backup, etc.), código muerto y rutas redundantes, lo cual complicaba la mantenibilidad.

 

Actual: Aún se observan numerosos archivos duplicados y backups en el repositorio, lo que indica que la limpieza no fue completa. Por ejemplo:

En src/app/api/users/profile/ existen múltiples variantes de la misma ruta: route.ts, route-fixed.ts, route-corregido-*.ts, etc.

Componentes con versiones paralelas: navbar.tsx y navbar-fixed.tsx (además de backups previos a mejoras), hero-section.tsx y hero-section-fixed.tsx, entre otros.

Hooks duplicados: useAuth.ts y useAuth-final.ts coexisten, al igual que useSupabaseAuth.ts (indicando intentos distintos de implementar la misma funcionalidad).

Archivos de semillas y scripts: varios seeds como seed.ts, seed-fixed.ts, seed-clean.ts, etc., y scripts con sufijo -fixed.mjs aparecen en el código.

Estos archivos parecen no ser utilizados en la ejecución actual, sino que permanecen como restos de iteraciones anteriores. Si bien no afectan directamente al runtime (asumiendo que solo se importa la versión final de cada módulo), su presencia puede generar confusión. Por ejemplo, un desarrollador podría editar el archivo incorrecto creyendo que está activo.

 

No se aprecia una política de limpieza activa en esta actualización: los archivos duplicados no fueron eliminados ni consolidados.

 

Conclusión: El código mantiene muchas referencias obsoletas y duplicadas. Se recomienda urgentemente depurar el repositorio eliminando archivos innecesarios y asegurando que cada funcionalidad tenga una única fuente de verdad. Estado: Pendiente.

4. Integración de Supabase Storage para imágenes (propiedades y avatares)

Anterior: Las imágenes de propiedades y avatares de usuario se estaban manejando en formato Base64 embebido, causando ineficiencias (tamaño elevado, problemas de rendimiento y almacenamiento en la BD). Se recomendó usar Supabase Storage para almacenar imágenes y guardar solo URLs o referencias en la base de datos.

 

Actual: Hubo progreso importante en este aspecto, aunque aún no está completamente integrado de punta a punta:

Buckets configurados: En la configuración de Supabase (supabase-config.json) se definen buckets llamados property-images y avatars, señal de que se preparó el almacenamiento de archivos externo.

Componente de carga de imágenes: Se creó un componente reutilizable ImageUploadUniversal (en src/components/ui/image-upload-universal.tsx) que utiliza la biblioteca de Supabase para subir imágenes a los buckets correspondientes. Este componente toma un userId, permite seleccionar múltiples archivos y, por cada imagen, genera un nombre único y realiza supabase.storage.from(bucket).upload(...) seguido de getPublicUrl. Tras subir, invoca onUploadComplete pasando la lista de URLs públicas obtenidas. Esto es exactamente el comportamiento esperado para integrar con Supabase Storage.

Persistencia en BD: El esquema Prisma ahora contempla en el modelo Property un campo images tipo String para guardar un JSON de URLs de imágenes. De hecho, en la ruta de creación de propiedad (/api/properties/create) se arma images: JSON.stringify(imagesArray) al guardar, en vez de almacenar Base64. Esto sugiere que el flujo previsto es: obtener URLs (probablemente de Supabase) y almacenarlas en la BD en formato JSON.

No obstante, encontramos un detalle importante: el formulario de Publicar Propiedad aún utiliza un componente distinto (ImageUpload en image-upload.tsx) que convierte las imágenes a Base64 para previsualización y las pasa tal cual en el array images. Actualmente, el backend no distingue si esas strings son Base64 o URLs; simplemente las guarda. Si el frontend no está utilizando el nuevo componente que sube a Supabase antes de enviar, podría seguir almacenando cadenas Base64 en la base de datos. En la ruta de creación, no hay lógica para procesar Base64 (ni llamada al API de Supabase), por lo que dependería totalmente de que el frontend ya provea URLs.

 

Situación actual: Parece que la integración quedó a medio camino. Se crearon las herramientas (buckets y componente de subida), pero en la página de publicación básica (/publicar) no se evidencia su uso. Es posible que la sección Publicar Premium vaya a usar ImageUploadUniversal (dado que esas propiedades podrían requerir subir fotos antes de pago), pero no encontramos una referencia directa en el código a su uso.

 

Conclusión: La infraestructura para usar Supabase Storage está Parcialmente resuelta. Se recomienda actualizar los formularios de carga de imágenes para utilizar la lógica de subida al bucket antes de crear la propiedad, evitando por completo almacenar Base64. Adicionalmente, en next.config.js debería añadirse el dominio de Supabase Storage a la lista de dominios permitidos para imágenes externas (actualmente solo figuran Unsplash, placeholder y localhost).

5. Políticas RLS (Row-Level Security) en Supabase

Anterior: Se indicó que era crucial habilitar y configurar las políticas de acceso a filas (RLS) en Supabase para asegurar las tablas (p.ej., que cada usuario solo pueda ver/editar sus propios datos en profiles/properties, etc.). No estaba claro si estaban activas o correctamente definidas.

 

Actual: El archivo de configuración supabase-config.json sugiere que las RLS están configuradas. Allí se listan las tablas y políticas, por ejemplo:

Tablas profiles y properties bajo la sección "tablas".

Políticas asociadas: "profiles": ["view_own", "update_own", "insert_own"] y "properties": ["view_active", "create_own", "update_own", "delete_own"]. Esto indica que existen reglas en Supabase para permitir que los usuarios visualicen solo sus perfiles, inserten/editen solo sus propiedades, etc., además de posiblemente permitir ver propiedades ajenas solo si están activas/publicadas.

El hecho de que en el código se use con éxito supabase.auth.getUser() y consultas filtradas sugiere que RLS está activa, ya que de otro modo las selecciones anónimas estarían bloqueadas. También vemos cómo en algunos casos se recurre a la clave de servicio (bypass RLS) para ciertas tareas administrativas, confirmando que RLS impone restricciones (de lo contrario, no haría falta usar la clave de servicio en backend).

 

Efectividad: Las políticas parecen correctamente definidas en Supabase; sin embargo, cabe señalar que en la implementación actual no siempre se aprovecha RLS debido al uso mixto de Prisma (con credenciales privilegiadas). Por ejemplo, al crear una propiedad con Prisma en el servidor, esa inserción se realiza con privilegios totales (usando DATABASE_URL de servicio), lo que ignora RLS. Esto no es un problema de seguridad en sí (porque el servidor controla la lógica), pero sí significa que parte del beneficio de RLS (control de acceso a nivel de BD) se elude en favor de lógica de aplicación.

 

Conclusión: Las RLS están Resueltas en cuanto a configuración. Para maximizar su efectividad, se podría considerar utilizar más el cliente Supabase con la sesión del usuario en operaciones comunes (dejar Prisma solo para casos especiales o administrativos), de forma que la BD siempre aplique sus reglas de seguridad. En resumen, las políticas existen y están activas; el siguiente paso es asegurar que la aplicación está alineada con ellas en todos los escenarios.

6. Sincronización del esquema de Prisma con la base de datos (migraciones, campos eliminados)

Anterior: La auditoría previa encontró discrepancias entre el esquema Prisma local y la base de datos real. En especial, se mencionó la necesidad de eliminar el campo password (ya que se migró a Supabase Auth) y asegurar que los campos/type mappings concuerden con Supabase (nombres en snake_case, tipos UUID, etc.). También se recomendó aplicar las migraciones pendientes para alinear el modelo con la BD.

 

Actual: Se observa una migración inicial (20250103000000_bootstrap) que define la estructura base en Supabase. En esa migración se crea la tabla profiles (id vinculada a auth.users, campos full_name, avatar_url, timestamps) y la tabla properties, entre otras (también se crean funciones y RLS policies según ese script). Esto indica que Prisma generó y aplicó una migración para la integración con Supabase, lo cual es positivo.

 

No obstante, persisten algunos problemas de sincronización:

Campo password: El modelo User en schema.prisma aún incluye password (tipo String). Esto es un rezago de la antigua implementación local de usuarios. Dado que ahora la autenticación está delegada a Supabase (y probablemente no se utiliza la tabla User), este campo debió ser removido. Tenerlo en el esquema puede causar confusión e incluso potenciales vulnerabilidades si accidentalmente se usa. Hasta donde pudimos verificar, no existe una migración que elimine dicho campo ni indicios de que se esté poblando (la tabla profiles/users en Supabase no lo tiene). Por tanto, Prisma y la base real divergen en este punto.

Unificación de tablas de usuario: Hay señales de que en el diseño actual se quiso unificar la información del usuario en una sola tabla users (posiblemente combinando profiles con datos adicionales). El hook useSupabaseAuth y las rutas API (/api/users/profile) hacen consultas a .from('users') obteniendo campos como full_name, avatar, occupation, age, user_type, company_name, license_number, etc.. Sin embargo, en la migración no se creó una tabla users explícitamente. Es probable que:

O bien la tabla profiles se haya ampliado con muchas de esos campos extra (pero esa migración inicial de profiles no los tenía).

O se creó manualmente una vista en Supabase llamada users que haga JOIN de profiles con otras tablas (por ejemplo, quizás unió profiles con las tablas User y Agent definidas en Prisma).

Otra posibilidad es que se optó por renombrar la tabla profiles a users en Supabase después de la migración inicial para simplificar (y ajustar las políticas RLS a esa nueva tabla).

Sin la confirmación directa del estado de la BD es difícil saberlo, pero el código sugiere que el proyecto espera una entidad users consolidada. Prisma, en cambio, aún define modelos separados: Profile, User, Agent por separado, y no conoce una tabla users unificada. Esto es una inconsistencia importante entre la capa de datos real y el ORM.

Campos y tipos consistentes: Prisma utiliza atributos @map para ajustar algunos nombres al snake_case de la BD (e.g. full_name y avatar_url en Profile). Eso está bien. Pero otros modelos, como User o Agent, no tienen esos mapeos en Prisma, sugiriendo que quizás ni siquiera existen en la base de datos real. Por ejemplo, Prisma cree que hay un User con campos camelCase (name, email, phone, etc.), pero Supabase probablemente no tenga esa tabla tal cual. Esto puede dar lugar a errores si Prisma intenta acceder a tablas o columnas inexistentes.

Conclusión: Se dio un paso en la sincronización al aplicar la migración inicial, pero no está completamente resuelto. El esquema Prisma todavía contiene elementos obsoletos (password en User, tablas posiblemente redundantes) y no refleja fidedignamente la estructura final en Supabase (tabla unificada de usuarios, campos extra en profiles/users). Es crucial realizar una limpieza y actualización del schema.prisma, eliminando modelos no usados y agregando cualquier cambio final de la BD (por ejemplo, incluir un campo role de usuario si se añadió en Supabase, o definir correctamente la vista users si se usa con Prisma). Actualmente, este desfase podría causar confusión a futuros desarrolladores e impedir migraciones consistentes. Estado: Parcialmente resuelto/Pendiente de ajuste fino.

7. Gestión del estado de sesión, visibilidad en Navbar y contexto de usuario

Anterior: El proyecto presentaba problemas al manejar el estado de autenticación del usuario – por ejemplo, la barra de navegación no reflejaba correctamente si el usuario estaba logueado o no, no había un contexto unificado para la sesión, etc. Se sugirió mejorar el manejo global de la sesión (posiblemente con un contexto o provider) para mostrar u ocultar elementos de UI según autenticación.

 

Actual: Se implementaron mejoras significativas en este frente:

AuthProvider: Existe un componente proveedor de autenticación (src/components/auth-provider.tsx) que envuelve la aplicación cliente. Este componente utiliza supabase.auth.onAuthStateChange para detectar cambios en el estado de sesión y ejecuta router.refresh() en cada cambio. Esto asegura que las partes de la UI que dependan de la sesión (incluyendo componentes server-side) se actualicen oportunamente cuando el usuario inicia o cierra sesión.

Hook de autenticación: Se desarrolló un hook personalizado useAuth() (y una variante useSupabaseAuth() que parece experimental) para gestionar el usuario actual. El hook useAuth utiliza el cliente de Supabase en el navegador para obtener la sesión actual (getSession()), luego llama a la API /api/users/profile para obtener el perfil completo del usuario. Mantiene en su estado interno el objeto user, un indicador loading y métodos como signOut. Además implementa un sistema de cache local (ProfilePersistence) para almacenar el perfil en localStorage, optimizando la carga en recargas de página. También maneja eventos de Supabase (SIGNED_IN, SIGNED_OUT, TOKEN_REFRESHED) para actualizar el estado.

Navbar dinámico: El componente de navegación (Navbar) ahora es un componente cliente que consume el hook useAuth. En su renderizado, comprueba isAuthenticated o la presencia de user para decidir qué mostrar. Efectivamente:

Si el usuario no está autenticado, la Navbar muestra botones de Login/Registro.

Si el usuario sí está autenticado, muestra el menú de usuario (desplegable de perfil) con opciones como cerrar sesión. Por ejemplo: <ProfileDropdown user={user} onSignOut={signOut} /> en el JSX de la Navbar, mientras que en el branch else se renderizan los links de Login/Registro.

Esta lógica asegura que la interfaz responde correctamente al estado de sesión en todo momento. Adicionalmente, funciones como signOut() llaman a supabase.auth.signOut() y luego hacen router.push('/login') limpiando el estado global y el cache, lo cual centraliza bien el proceso de logout.

 

Conclusión: La gestión de la sesión y la integración con la UI se han Resuelto adecuadamente. Ahora hay un mecanismo consistente para obtener el usuario logueado y compartirlo entre componentes. El Navbar refleja con precisión el estado (mostrando elementos adecuados según sesión). Estos cambios corrigen los problemas identificados previamente de forma satisfactoria.

8. Proceso completo de publicación de propiedades (básicas vs premium), pago y webhook de MercadoPago

Anterior: Se identificó que el flujo para publicar propiedades premium (con pago mediante MercadoPago) no estaba concluido o presentaba fallos. Aspectos como la creación de la preferencia de pago, el manejo de la respuesta (éxito, pendiente, fallo) y el procesamiento del webhook para confirmar el pago estaban incompletos. También la publicación estándar necesitaba revisión en cuanto a asignación de usuario, guardado de datos, etc.

 

Actual: Dividimos el análisis en Publicación básica y Publicación premium:

Publicación básica (gratuita): Al publicar una propiedad normal, el flujo en /publicar reúne los datos y los envía al endpoint REST /api/properties/create. En este endpoint:

Se verifica que el usuario esté autenticado (getAuthenticatedUser) antes de proceder.

Se validan campos obligatorios (título, descripción, precio, etc.) y formatos (precio numérico positivo).

Se contempla un campo plan en el payload (posiblemente para distinguir publicaciones premium, aunque en la creación básica no se usa para almacenar nada, solo como metadata).

Se crea o busca un agente por defecto (Misiones Arrienda) si no hay uno ya. Esto sugiere que, si el usuario que publica no es una inmobiliaria/agent, el sistema asigna un agente genérico a la propiedad. Es una manera de tener siempre un agente relacionado a la propiedad (posiblemente requerido por el esquema de datos).

Finalmente, se realiza prisma.property.create({...}) con los datos proporcionados. Aquí se incluyen valores por defecto para algunos campos:

currency por defecto "ARS" si no viene.

province por defecto "Misiones", postalCode fijo "3300".

featured por defecto false, status por defecto "AVAILABLE".

Las listas amenities y features se guardan como JSON (si no se proveen, se ponen algunos valores genéricos como agua, electricidad, etc.).

Imágenes: Como mencionamos en el punto 4, si el array de images viene vacío, rellenan con unas imágenes placeholder (/images/properties/default-1.jpg, etc.). Si viene con elementos (supuestamente URLs de Supabase), se almacena tal cual en JSON. No hay conversión en este punto, asume que lo que llega ya es utilizable.

Asociación con el usuario: Llama la atención que en la creación no vimos explícitamente un campo userId asociando la propiedad al usuario que la publica. Quizá se omite en el snippet mostrado, o la asociación ocurre a través del agente (por ejemplo, si cada usuario tiene un agente propio). Esto debería confirmarse, pero es importante que la propiedad quede ligada al autor para aplicar RLS (create_own, update_own). Si se usa el agente por defecto en todos los casos, ¿cómo se distingue la propiedad de cada usuario? Es posible que haya una lógica no visible donde, si el usuario es de tipo "dueño directo", él mismo se considere el agente de su propiedad. Dado que no lo vemos, es un posible punto pendiente aclarar: la RLS create_own en properties suele basarse en un user_id o similar.

En síntesis, la publicación básica ahora valida y guarda correctamente la mayoría de campos, evitando datos vacíos o formatos incorrectos.

Publicación premium (con pago MercadoPago): Para las propiedades que requieren pago (destacadas), se implementaron endpoints y páginas adicionales:

Al elegir un plan premium, el frontend probablemente llama al endpoint POST /api/payments/create-preference. Este endpoint debería comunicarse con MercadoPago para generar una preferencia de pago (es decir, un checkout con importe, descripción, etc.).

En el código actual, create-preference está escrito para aceptar datos como items, payer, back_urls, metadata, propertyId, etc., y planea devolver la respuesta de MercadoPago (ID de preferencia, link de pago). Se nota la intención de integrar la SDK de MercadoPago (incluso hay un módulo mercadopago.ts con credenciales).

Hallazgo importante: Actualmente la implementación de create-preference devuelve un mock en lugar de llamar realmente a MercadoPago. En el código se ve un comentario // Por ahora, devolvemos un mock response y efectivamente responde con un id: 'mock-preference-id' y una URL simulada. Esto indica que, por el momento, no se está creando una preferencia real; tal vez para pruebas se dejó hardcodeado. En producción, obviamente, esto debe reemplazarse por la llamada real a MercadoPago (utilizando la SDK o API REST con la MERCADOPAGO_ACCESS_TOKEN real).

Las páginas de resultado del pago (/payment/success, /payment/pending, /payment/failure) están implementadas para recibir la información de la URL (MercadoPago suele retornar parámetros en la query) y mostrar mensajes al usuario. Estas páginas existen en el código, lo cual es bueno.

Webhook de MercadoPago: Se configuró en la preferencia (mock) un notification_url que apunta a /api/payments/webhook. Este endpoint de webhook está definido y recibe notificaciones POST de MercadoPago. En la implementación actual:

Lee el cuerpo con id, topic o type del evento.

Si topic/type === 'payment', intenta verificar el pago mediante verifyPayment(id) usando la librería MercadoPago. En caso de éxito, obtiene paymentInfo con detalles, incluyendo status y external_reference.

Luego, según el status (approved, pending, rejected, cancelled), solo hace un log por consola y un TODO para actualizar la base de datos. No realiza aún ninguna actualización real. Los comentarios sugieren que se debería, por ejemplo, marcar la propiedad como pagada/destacada cuando el pago es approved, o guardar un registro de pago en la tabla Payment.

Finalmente retorna NextResponse.json({ received: true }) para confirmar recepción.

Procesamiento final de la propiedad premium: Aquí vemos que todavía falta la parte crítica: tomar ese paymentInfo y aplicarlo. Lo esperable sería:

Cambiar el campo featured o plan de la propiedad a activo (ej: status = 'PREMIUM' o similar) si pagado.

Insertar un registro en la tabla Payment (ya existe un modelo Payment en Prisma) con los datos de la transacción (ids de MercadoPago, monto, referencia externa que podría ser el propertyId).

Quizá enviar una notificación al usuario o actualizar algún contador.

Remover/eliminar la propiedad si pago fallido? O notificar al usuario para reintentar.

Dado que nada de esto está implementado todavía (solo logs), el flujo premium, si bien delineado, no concluye automáticamente. En otras palabras, aunque el usuario pague, la propiedad no cambia su estado en la base de datos porque el webhook no lo persiste. Esto requerirá atención antes de lanzar a producción.

Conclusión: El proceso de publicación ha mejorado en cuanto a la ruta de creación de propiedades estándar (validaciones, estructura de datos), pero el flujo premium sigue Parcialmente resuelto. Existen todos los componentes (páginas de confirmación, endpoints para pago, webhook), pero con implementación incompleta (uso de mocks y falta de persistencia en webhook). Antes de producción es imprescindible conectar realmente con MercadoPago (usando las credenciales en .env) y completar la lógica de actualización de base de datos tras el pago. En su estado actual, las propiedades premium no se diferenciarían de las gratuitas más allá del intento de pago inicial.

9. Remoción de datos de prueba, mocks o configuraciones de desarrollo

Anterior: Se detectaron datos de prueba (usuarios, propiedades ficticias), mocks temporales y banderas de desarrollo que debían ser eliminados o deshabilitados al preparar el proyecto para producción.

 

Actual: Se tomaron acciones para limpiar la mayoría de datos de ejemplo:

Los archivos de seed ahora están orientados a un entorno limpio. Por ejemplo, prisma/seed.ts hace upsert de usuarios de muestra, pero se creó una variante seed-clean.ts donde probablemente estos inserts fueron removidos para un entorno vacío. Además, mock-data.ts define mockProperties = [] y mockAgents = [] (arreglos vacíos), indicando que han optado por no cargar propiedades de ejemplo por defecto.

Varios datos ficticios se eliminaron: ya no vemos referencias a "John Doe" u otros placeholders en el código. El único lugar con valores de ejemplo son los placeholders de imágenes y algunos textos (que no afectan datos reales).

Variables de desarrollo: en .env.example, NODE_ENV está como "development" solo como muestra. Para producción se espera que se ponga "production". No se encontraron credenciales reales expuestas en el repositorio (las keys de Supabase en el config parecen reales, pero posiblemente son de un proyecto de testing).

Mocks restantes: El punto crítico de mocks que aún persiste es el mencionado en el flujo de pago (preferencia de MercadoPago devuelve valores simulados). Ese es un mock de integración más que de datos. Aparte de eso, no parece que se estén usando datos de prueba en la app en producción.

Configuraciones de desarrollo: Por ejemplo, antes podía haber toggles para ignorar ciertos procesos en dev. Ahora, con la configuración de Vercel/Next, no se aprecian flags de desarrollo problemáticas. Incluso el codebase incluye un archivo vercel.json para configuración del deploy.

Conclusión: La aplicación se ve mayormente limpia de datos de prueba. No se cargan elementos ficticios en el estado inicial. Solo queda asegurarse de quitar cualquier respuesta simulada o lógica condicional de desarrollo antes de la versión final (e.g., retirar el mock de MercadoPago mencionado). Estado: Resuelto en cuanto a datos de prueba (con la salvedad del mock técnico del pago a corregir).

10. Variables de entorno, configuración de imágenes externas y documentación

Anterior: Se pidió revisar que las variables de entorno necesarias estuvieran correctamente listadas (por ejemplo en un .env.example), que Next.js permitiera las fuentes de imágenes externas requeridas, y que existiera documentación actualizada (README, instrucciones de despliegue, etc.).

 

Actual:

Variables de entorno: Existe un archivo .env.example completo y bien documentado. Incluye secciones para Supabase (URL, anon key, service key), NextAuth (aunque parece remanente de un intento, probablemente no se usa ya NextAuth pero la variable está), configuración SMTP para emails, credenciales de MercadoPago y la variable NODE_ENV. Cada variable trae comentarios descriptivos y valores de ejemplo, lo cual facilita la configuración en distintos entornos. Esto cumple con lo esperado: ahora un nuevo desarrollador o el mismo equipo puede revisar .env.example y saber qué claves debe proveer.

Configuración de imágenes externas: En next.config.js se define la propiedad images.domains con dominios permitidos como images.unsplash.com, via.placeholder.com y localhost. Además se configuran patrones remotos para Unsplash y Placeholder. Falta incluir el dominio de Supabase Storage (por ejemplo qfeyhaaxyemmnohqdele.supabase.co u otro) de donde se servirán las imágenes de propiedades y avatares. Si las imágenes subidas a Supabase se van a mostrar usando el componente Next <Image> (que optimiza imágenes), es necesario agregar el dominio de public URLs de Supabase. Actualmente, de no hacerse, Next.js bloquearía esas cargas externas en tiempo de ejecución. Por seguridad, se recomienda incluirlo. Si por el contrario usarán <img> estándar, no es estrictamente necesario pero pierde optimizaciones. Dado que ya configuraron otros dominios, probablemente fue un descuido no agregar Supabase.

Documentación (README): El README.md del proyecto está actualizado con la descripción de la plataforma, sus características (gestión de propiedades, sistema de pagos, comunidad, etc.), lo que indica un esfuerzo por documentar la funcionalidad. Sería bueno incluir en el README instrucciones básicas de instalación y ejecución (no vimos esa sección en el fragmento, pero se intuye que puede estar más abajo). También conviene mencionar la necesidad de configurar las variables de entorno antes de desplegar.

Otras docs: Hay un archivo TODO.md, tal vez para seguimiento interno de pendientes, y algunos README en subdirectorios (por ejemplo, en docs/components/comunidad y en src/lib/security), lo cual es útil para entender ciertas partes.

Conclusión: La preparación de entorno y documentación está casi resuelta. .env.example y README proveen lo necesario. Solo falta asegurarse de incluir todos los detalles finales (ej. dominio de imágenes externo para Supabase en la config, instrucciones de deploy en documentación, eliminar variables no usadas como NextAuth si ya no aplica). En general, la documentación va en buena dirección. Estado: Resuelto (con mínimas correcciones sugeridas).

Sugerencias finales

Tras la comparación, aunque muchos puntos fueron abordados satisfactoriamente, quedan algunos pendientes o susceptibles de mejora. A continuación, se listan sugerencias finales para llevar el proyecto al mejor estado:

Eliminar código muerto y duplicado: Limpiar el repositorio borrando archivos obsoletos (*-fixed.ts, *.backup.*, hooks/comp duplicados). Mantener solo las versiones vigentes para reducir confusión y riesgo de utilizar código incorrecto.

Unificar el modelo de usuario en Prisma: Remover el campo password y cualquier modelo de usuario que no corresponda al esquema actual en Supabase. Si la tabla unificada de usuarios es profiles renombrada o una vista users, ajustar el schema.prisma y generar migraciones para reflejarlo. Documentar claramente cómo se maneja el rol admin (vía columna en profiles, user metadata, o tabla aparte) e incluirlo en el esquema.

Asegurar protección de todas las rutas admin: Añadir verificación de rol admin en todos los endpoints de administrador (stats, activity, etc.). También considerar proteger la ruta /admin en el middleware global para que solo usuarios logueados (idealmente admins) puedan cargar esas páginas.

Completar integración de Supabase Storage: Modificar el formulario de Publicar (y cualquier subida de avatar) para usar el componente que sube imágenes a Supabase antes de enviar. Al guardar propiedades, almacenar solo URLs públicas (no Base64). Añadir el dominio público de Supabase Storage en next.config.js para evitar problemas con imágenes externas.

Finalizar flujo de pagos MercadoPago: Reemplazar respuestas mock por llamadas reales al SDK/API de MercadoPago usando las credenciales. Implementar la lógica en el webhook para actualizar la base de datos: crear registros en la tabla Payment, marcar la propiedad como "destacada" o pagada exitosamente, etc. Probar todo el ciclo (crear preferencia → redirigir a pago → recibir webhook → ver reflejado en la app).

Verificar asociación usuario-propiedad: Confirmar que cada propiedad quede asociada al usuario que la creó (sea directamente con un userId o vía un agentId único). Esto es crucial para que las políticas RLS de propiedades (create_own, update_own) funcionen y para que en el futuro un usuario pueda ver/editar solo sus propiedades.

Pruebas finales y eliminación de modo dev: Realizar pruebas integrales en un entorno de staging con las variables de entorno reales. Revisar que no queden console.log excesivos o TODO importantes sin resolver en producción. Cambiar NODE_ENV a production en el deploy final para activar optimizaciones de Next.js.

Actualizar documentación según cambios finales: Incluir en el README pasos de despliegue, cómo correr migraciones Prisma contra Supabase, y anotar cualquier configuración especial (p. ej. habilitar RLS en Supabase ya se hizo, pero mencionar por transparencia). Remover del README variables no utilizadas (si NextAuth ya no se usa, podría limpiarse esa sección para no generar confusión).

Con estas acciones, el proyecto quedará plenamente alineado con las mejores prácticas y las recomendaciones de la auditoría previa, facilitando su transición a un entorno de producción estable y seguro. Cada punto pendiente resuelto fortalecerá la plataforma en términos de seguridad, mantenibilidad y rendimiento. ¡Buen trabajo hasta ahora y ánimo con los últimos ajustes!